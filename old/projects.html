<!DOCTYPE html>
<html>
<head>
    <title>Projects Annika Kouhia</title>
    <link rel="stylesheet" href="basepage.css">
    <link rel="stylesheet" href="CSSprojects.css">
</head>

<body>
    <div class = "fullbar">
        <a class = "heading" href="index.html">Home</a>
        <a class = "heading" href="about.html">About</a>
        <a class = "navHead" href="projects.html">Projects</a>
        <a class = "heading" href="contact.html">Contact</a>
    </div>
    
    <h1 class="box">Projects</h1>

    <div class = "fullcontents">
        <a class = "contents" href="#CS50">Tiny Search Engine — CS50</a>
        <a class = "contents" href="#CS10">Part of Speech Mapping — CS10</a>
        <a class = "contents" href="#CS01">Dartmouth Map — CS01</a>
    </div>
    
        <div class = projTitle>
        <a name="CS50">Tiny Search Engine</a>
    </div>
    
    <div class = "caption"><img class="projImg" src="TSE%20Query.png">
        <p class = "but">What it does:<br></p>
            Given a root webpage and a certain depth of search, this program allows users to enter search queries, and receive back any webpages which have that query somewhere on the page. The webpage must be within the given depth of links from the original webpage, and will be scored based on how frequently the query appears. The results are sorted by highest to lowest score.
        <br><br>
        <p class = "but">What I was given:<br></p>
            I was given access to certain "safe" root webpages designed specifically for this project so as to not overwhelm the internet or our tiny search engine while conducting queries. The project was also broken down into a Crawler, Indexer, and Querier for ease of organization. <br><br>
        
        <button class = "but" type="button" onclick='document.getElementById("moreCS50").style.display = "block"'>How I coded it ▼</button>
        
        <p class = "caption" style="display:none" style="text-indent: 30px" id = "moreCS50">
            Our Crawler began with our root webpage, and scanned it for links to each webpage it connected to, and then scanned webpages each of those connected to, and webpages each of those connected to, etc. until the maximum depth was achieved. As it crawled through webpages and links, it documented each page by saving a corresponding text file with the page's URL on the first line, the depth from the root webpage on the second, and the page's HTML starting on the third. Each document was named as the number webpage that had been searched, the first saved as 1, the second as 2, etc.<br>
            Our Indexer then took over, creating a master hashtable of each word seen in any HTML, and then pairs of values associated with that word. The first value in each pair was the document number in which that word was found, and the second value in the pair was the number of times that word was found in that document. Once our hashtable was created, we wrote it out to a file in a concise format that allowed for an easy visual summary of our index. <br>
            Finally, our Querier actually handled incoming queries from the user, splicing apart and stringing together queries with "and" and "or" throughout. Itthen tehn  then searched our index for data that matched the query, and eventually summarized findings and outputted to the user.
        </p>
    </div>
    



   
    

    
    
    <div class = projTitle>
        <a name="CS10">Part of Speech Mapping: Coded in Java</a>
    </div>
    
    <div class = "caption"><img class="altProjImg" src="POS.png">
        <p class = "but">What it does:<br></p>
            I completed this project with my lovely partner Morgan Sorbaro during CS10: Object Oriented Programming. This program prompts the user to enter a sentence, and then in response will output the part of speech that corresponds with each word in the sentence. For testing purposes, it can also be run with a text file input, and check its answers against a corresponding "answer bank", finally outputting the number it got correct. Our final submission scored 59/59 on a smaller test set (100% accuracy) and 562786/579662 on a larger test set (97% accuracy).
        <br><br>
        <p class = "but">What I was given:<br></p>
            To begin this lab, we were given access to Brown Training Files--massive text files which Brown University had created corresponding files for, which documented the part of speech for each word in the original file. We were also given smaller, simpler training files, and both small and large testing files.
        <br><br>
        
        <button class = "but" type="button" onclick='document.getElementById("moreCS10").style.display = "block"'>How I coded it ▼</button>
        
        <p class = "caption" style="display:none" style="text-indent: 30px" id = "moreCS10">
            We first used two methods to read our training files and add each seen word to a master list of words, and each seen part of speech (POS) to a master list of parts of speech. We went through our master list of POS and for each POS, looked at the POS that followed it in the list. We created a map of POS keys, and values that were a map of each unique POS we saw follow, and the number of times we saw it follow. For example, if we saw DET, TO, DET, ADJ, DET, ADJ, we would know that DET was followed 1 time by TO and 2 times by ADJ. We then converted mere number of follows to frequencies--so 1 changed to 1/3 and 2 changed to 2/3. After creating this map, did the same but with POS keys to specific words that followed (accessed by looking at the master list of words at that index) and their frequencies. We then used the Viterbi Algorithm, which basically took into consideration the probability that each type of POS followed the one in question (1/3 chance TO, 2/3 chance ADJ) and the probability of the following word being different POS ('run' as a noun vs. 'run' as a verb). We then kept track of many different potential "paths", grooming our tree of different sentence structures as possible. As we went through each potential series of POSs we kept were careful to keep a map that allowed us to backtrace at the end. Upon reaching the conclusion of the test data or inputted sentence, the program found the path that was the most likely, backtraced it, and printed out the results. We also wrote helper methods to compare our answer to a text document with the correct answers in case the user wanted to test against documented data. 
        </p>
    </div>

    
    
    
    
    <div class = projTitle>
        <a name="CS01">Dartmouth Map: Coded in Python</a>
    </div>
    
    <div class = "caption"><img class="projImg" src="DartMap.png">
        <p class = "but">What it does:<br></p>
            One of my favorite projects from CS01: Introduction to Programming and Computation, this program allows a user to navigate Dartmouth campus using only the most efficient routes between start and goal locations. Users can click on a beginning location, and hover over any other location to visually receive the shortest path between the two points.
        <p class = "but"><br>What I was given:<br></p>
            To begin this lab, I was given acccess to a pdf version of a standard campus map. I was also given a corresponding text file which held the name of each location (or "vertex") on campus, its x and y coordinates in pixels as corresponded to the pdf map, and a list of the names of its immediate, neighboring locations.<br><br>
        
        <button class = "but" type="button" onclick='document.getElementById("moreCS01").style.display = "block"'>How I coded it ▼</button>
        
        <p class = "caption" style="display:none" style="text-indent: 30px" id = "moreCS01">
            I first set about analyzing the text file, parsing, slicing, and splitting the data, and saving each location's line of information in a useful "vertex" object I created separately. Once I had translated the text into objects, I saved the objects in a dictionary, where the keys were each location's name, and the corresponding value was the corresponding vertex object. I then programmed a breadth first search method which would take a start and goal vertex, and return a list of vertices that marked the shortest between the two, after analyzing potential routes via shared neighbors. Finally, I animated the software, creating a simple, user-friendly interface which allowed users to quickly map the optimal path between any two locations on campus.
        </p>
    </div>
        
</body>
</html>